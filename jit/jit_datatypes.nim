# License Apache v2
# Copyright 2018, Mamy AndrÃ©-Ratsimbazafy

# Each code fragment is allocated to it's own page(s)
# This probably waste a lot of space (4096-bit)
# but this allows mprotect granularity, as it's page-wide

import
  ./jit_osalloc,
  hashes, tables

func round_step_up*(x: Natural, step: static Natural): int {.inline.} =
  ## Round the input to the next multiple of "step"
  when (step and (step - 1)) == 0:
    # Step is a power of 2. (If compiler cannot prove that x>0 it does not make the optim)
    result = (x + step - 1) and not(step - 1)
  else:
    result = ((x + step - 1) div step) * step

type
  Register_X86_64* = enum
    # AX in 16-bit, EAX in 32-bit, RAX in 64-bit
    # Registers are general purposes but some have specific uses for some instructions
    # Special use of registers: https://stackoverflow.com/questions/36529449/why-are-rbp-and-rsp-called-general-purpose-registers/51347294#51347294
    rAX = 0b0_000  # Accumulator
    rCX = 0b0_001  # Loop counter
    rDX = 0b0_010  # Extend accumulator precision
    rBX = 0b0_011  # Array index
    rSP = 0b0_100  # Stack pointer                            - In ModRM this triggers SIB addressing
    rBP = 0b0_101  # Stack base pointer (stack frame address) - In ModRM this triggers RIP addressing (instruction pointer relative) if mod = 0b00
    rSI = 0b0_110  # Source index for string operations
    rDI = 0b0_111  # Destination index for string operations
    r8  = 0b1_000
    r9  = 0b1_001
    r10 = 0b1_010
    r11 = 0b1_011
    r12 = 0b1_100  # In ModRM this triggers SIB addressing
    r13 = 0b1_101  # In ModRM on x86_64, this triggers RIP addressing (instruction pointer relative) if mod = 0b00
    r14 = 0b1_110
    r15 = 0b1_111

  Register* = Register_X86_64

  JitFunction*[P: static set[MemProt]] = ref object
    call*: proc(){.cdecl.}
    adr: pointer
    len: int

  Label* = object
  CodePos* = int

  Assembler*[R: Register] = object
    code: seq[byte]                        # Generated bytecode
    clobbered_regs: seq[R]                 # Dirty registers that need to be saved/restored
    labels: seq[Label]                     # Track labels used to replace by their address
    labels_pos: seq[CodePos]               # Labels target
    labels_use: Table[Label, seq[CodePos]] # Bytecode to rewrite with the actual label location

  # Note on caching mechanism.
  # This is a hard problem, with 2 potential rewards:
  #    1. Saving on memory allocation for the JIT code
  #    2. Reducing CPU overhead by avoiding unnecessary compilation.
  #
  # However:
  #    1. A caller/user has more context for its usecase
  #       and could pass the JitFunction around once it's compiled once.
  #       Even if the caller is another library, caching at the higher-level library
  #       probably makes most sense.
  #
  #    2. As we go through the dynamic code generation we keep a hash of
  #       the bytecode generated. Finally if the hash already exists in the code cache
  #       we can just not copy the bytecode and reuse the mmap region containing the
  #       same bytecode.
  #       ----
  #       This reduces unnecessary memory allocation and saves a copy,
  #       but we still incur compilation overhead + hashing added on top.
  #       ----
  #       Hashing the AST in one pass and geneating the bytecode in another
  #       (instead of just hashing the bytecode) will render the codegen quadratic
  #       + we also need to define a runtime AST.
  #
  #    3. Alternatively, we could use the compile-time AST and derive a cache key from it
  #       with 2 different alternatives:
  #         A1. Parsing the Nim AST tree and computing a base hash at compile-time
  #             There is a need to detect the runtime immediates and
  #             add their runtime values to the hash.
  #         A2. Alternatively each proc will do the following pseudocode
  #             ```
  #             proc mov(a: static Assembler, reg: static Register, imm32: uint32) =
  #               const rex = rex_prefix(w = true, r = false, x = false, b = false)
  #               const opcode = 0xC7
  #               const modrm = modrm(Direct, reg, false)
  #
  #               block:                      # Compile-time part
  #                 a.hash = a.hash !& rex
  #                 a.hash = a.hash !& opcode
  #                 a.hash = a.hash !& reg
  #                 a.hash = a.hash !& 0      # Placeholder hashing as immediate is nly known at runtime
  #                 a.immediates.add imm32    # Add the immediate sym/ident to a seq[NimNode]
  #                 a.clobbered_regs.add reg
  #
  #               block:                      # Run-time part
  #                 a.code.add rex
  #                 a.code.add opcode
  #                 a.code.add modrm
  #                 a.code.add cast[array[4, byte]](imm32)
  #             ```
  #             And we can finalise the compile-time hash at runtime
  #             with the seq[NimNode] of immediates.
  #         ------------
  #         Pros & Cons:
  #           A1. The runtime cost is minimal, however separating the immediate symbols
  #               from procs, temporaries, enums symbols seems tricky.
  #           A2. There is one challenge to have a compile-time and run-time part
  #               for "Assembler", this probably requires macro everywhere of procs
  #               which is trivial.
  #               Separating run-time immediates from the rest of symbols is easy
  #               However this cannot deal easily with runtime branching in codegen:
  #               ```
  #               if runtime_bool:
  #                 a.mov(rax, 1)
  #               else:
  #                 a.mov(rbx, 2)
  #               ```
  #               1. Both branches will participate in the base compile-time hash
  #                  meaning even if there is already a `a.mov(rax, 1)` fragment in
  #                  the code cache, a code with branching will still generate its own.
  #                  That's an OK price.
  #               2. `runtime_bool` needs to contribute to the final hash as well
  #                  - Easiest would be asking the caller which runtime symbols
  #                    participate in control flow. Caveat with non-determinstic proc below.
  #                  - Alternatively, a static analysis that determines all
  #                    runtime values that participate in control flow.
  #                    Nim runtime control structures are:
  #                      - `if`, `case`, `for`, `while`, `break`
  #                    Hashing values known at compile-time is not an issue.
  #                    The tricky part are mutable vars and non-deterministic procs,
  #                    for example in a while loop:
  #                    ```
  #                    var i = 0
  #                    while i < foo.len:
  #                      a.mov(rax, 1)
  #                      inc i
  #                    ```
  #                    ---> we need to hash `foo.len` but not `i`
  #                    ```
  #                    while foo.len > 0:
  #                      a.mov(rax, foo.pop())
  #                    ```
  #                    ---> we need to hash `foo` but not `foo.len`
  #                    ```
  #                    while nondeterministic(foo) > 0:
  #                      a.mov(rax, 1)
  #                    ```
  #                    ---> no solution, each call to nondeterminstic(foo)
  #                         must be hashed
  #
  # Note that this caching problem is the same problem as
  #   - static computation graph (define-and-run) like Tensorflow
  #   - dynamic computation graph (define-by-run) like PyTorch
  # in deep learning with the same tradeoffs:
  #   - With static graphs you need a DSL to deal with control flow, i.e. inflexibility.
  #   - with dynamic graphs you need to generate the graph repeatedly and cannot cache it.
